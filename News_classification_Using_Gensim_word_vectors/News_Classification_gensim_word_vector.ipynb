{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e2f940-2dff-4b16-bacf-700e8412ac9f",
   "metadata": {},
   "source": [
    "- Text Classification USing Gensim Word Embeddings\n",
    "\n",
    "- Loading Google News Word2vec model from gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4c3f3-eb82-46f0-aae9-5ed972cf8715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a9a9c-cac4-4435-b4e6-6e27f2a7fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61d41d-7878-4108-bacd-f07206a76576",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_great = wv[\"great\"]\n",
    "wv_good = wv[\"good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece7c05-c931-41e3-9cca-1341053fb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_great.shape, wv_good.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ce43d-7f59-4499-87b2-2c82ba182254",
   "metadata": {},
   "source": [
    "\n",
    "Fake vs Real News Classification Using This Word2Vec Embeddings\n",
    "\n",
    "    Fake news refers to misinformation or disinformation in the country which is spread through word of mouth and more recently through digital communication such as What's app messages, social media posts, etc.\n",
    "\n",
    "    Fake news spreads faster than real news and creates problems and fear among groups and in society.\n",
    "\n",
    "    We are going to address these problems using classical NLP techniques and going to classify whether a given message/ text is Real or Fake Message.\n",
    "\n",
    "    We will use glove embeddings from spacy which is trained on massive wikipedia dataset to pre-process and text vectorization and apply different classification algorithms.\n",
    "\n",
    "Dataset\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
    "\n",
    "    This data consists of two columns. - Text - label\n",
    "\n",
    "    Text is the statements or messages regarding a particular event/situation.\n",
    "\n",
    "    label feature tells whether the given text is Fake or Real.\n",
    "\n",
    "    As there are only 2 classes, this problem comes under the Binary Classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460f9f5-f453-40c8-9457-80e27fb01f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#read the dataset with name \"Fake_Real_Data.csv\" and store it in a variable df\n",
    "df = pd.read_csv(\"fake_and_real_news.csv\")\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(df.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b1b67-4f84-44e1-b4ec-d21520d711e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the distribution of labels \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bce489-499d-4a55-9cf1-9fa9783a4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the new column which gives a unique number to each of these labels \n",
    "\n",
    "df['label_num'] = df['label'].map({'Fake' : 0, 'Real': 1})\n",
    "\n",
    "#check the results with top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac18ef-0432-4ebd-8279-ca5cdcfcb31e",
   "metadata": {},
   "source": [
    "\n",
    "Now we will convert the text into a vector using gensim's word2vec embeddings.\n",
    "We will do this in three steps,\n",
    "\n",
    "    Preprocess the text to remove stop words, punctuations and get lemma for each word\n",
    "    Get word vectors for each of the words in a pre-processed sentece\n",
    "    Take a mean of all word vectors to derive the numeric representation of the entire news article\n",
    "\n",
    "First let's explore get_mean_vector api of gensim to see how it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e5c29-da13-4286-a447-8428764bd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.mean([wv_good, wv_great],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e9371-afef-4a07-9fef-e64870d5dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_good[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d62cc-9fc3-412e-8b62-3d276ad125d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_great[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7b358-1d3a-4bbd-a5c0-eb3eb741135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d769a39-d6c0-4a83-ae39-3c3f36da5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = wv.get_mean_vector([\"good\", \"great\"],pre_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2fd9e-b5fb-4f83-9bdc-7736b817cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a14403-9986-48a3-81f8-e05f81435f94",
   "metadata": {},
   "source": [
    "Now let's write the function that can do preprocessing and vectorization both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a47c9-2028-4a2f-a61b-05cd10d76c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\") # if this fails then run \"python -m spacy download en_core_web_lg\" to download that model\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21923c27-eff7-4850-9545-7d498453b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = preprocess_and_vectorize(\"Don't worry if you don't understand\")\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c0e55-1b78-4d15-a9bc-57ae6c460fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this query takes few minutes, so go get some walk :)\n",
    "\n",
    "df['vector'] = df['Text'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49e350-f50b-443f-88ab-b670ddd7825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462cd629-62f4-4315-bd59-59a3cb3f99ac",
   "metadata": {},
   "source": [
    "# Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88376b51-7a0c-4dd0-9b1c-b2afdcfa6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.vector.values, \n",
    "    df.label_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.label_num\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35892cb4-ca01-425a-b8b3-f9a45fe8e907",
   "metadata": {},
   "source": [
    "Reshaping the X_train and X_test so as to fit for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540223c-7456-48bf-a493-934c77d133f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train before reshaping: \", X_train.shape)\n",
    "print(\"Shape of X_test before reshaping: \", X_test.shape)\n",
    "\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "\n",
    "print(\"Shape of X_train after reshaping: \", X_train_2d.shape)\n",
    "print(\"Shape of X_test after reshaping: \", X_test_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe2039b-e0b2-43ea-92f4-26c386322ee7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Train Machine Learning Model\n",
    "\n",
    "I tried Random forest, decision tree, naive bayes etc classifiers as well but gradient boosting gave the best performance of all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423a984-1108-4dfd-9b0d-053d3d1c3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547f62b-de03-4f28-b4d5-9bb3dfd41a89",
   "metadata": {},
   "source": [
    "Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffa85b-968a-49aa-933a-62f9f4dca897",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news = [\n",
    "    \"Michigan governor denies misleading U.S. House on Flint water (Reuters) - Michigan Governor Rick Snyder denied Thursday that he had misled a U.S. House of Representatives committee last year over testimony on Flintâ€™s water crisis after lawmakers asked if his testimony had been contradicted by a witness in a court hearing. The House Oversight and Government Reform Committee wrote Snyder earlier Thursday asking him about published reports that one of his aides, Harvey Hollins, testified in a court hearing last week in Michigan that he had notified Snyder of an outbreak of Legionnairesâ€™ disease linked to the Flint water crisis in December 2015, rather than 2016 as Snyder had testified. â€œMy testimony was truthful and I stand by it,â€ Snyder told the committee in a letter, adding that his office has provided tens of thousands of pages of records to the committee and would continue to cooperate fully.  Last week, prosecutors in Michigan said Dr. Eden Wells, the stateâ€™s chief medical executive who already faced lesser charges, would become the sixth current or former official to face involuntary manslaughter charges in connection with the crisis. The charges stem from more than 80 cases of Legionnairesâ€™ disease and at least 12 deaths that were believed to be linked to the water in Flint after the city switched its source from Lake Huron to the Flint River in April 2014. Wells was among six current and former Michigan and Flint officials charged in June. The other five, including Michigan Health and Human Services Director Nick Lyon, were charged at the time with involuntary manslaughter\",\n",
    "    \" WATCH: Fox News Host Loses Her Sh*t, Says Investigating Russia For Hacking Our Election Is Unpatriotic This woman is insane.In an incredibly disrespectful rant against President Obama and anyone else who supports investigating Russian interference in our election, Fox News host Jeanine Pirro said that anybody who is against Donald Trump is anti-American. Look, it s time to take sides,  she began.\",\n",
    "    \" Sarah Palin Celebrates After White Man Who Pulled Gun On Black Protesters Goes Unpunished (VIDEO) Sarah Palin, one of the nigh-innumerable  deplorables  in Donald Trump s  basket,  almost outdid herself in terms of horribleness on Friday.\"\n",
    "]\n",
    "\n",
    "test_news_vectors = [preprocess_and_vectorize(n) for n in test_news]\n",
    "clf.predict(test_news_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f3e1c-20b8-4230-9ebc-edabb11586f0",
   "metadata": {},
   "source": [
    "Confusion Matrix for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff15e6-6fa0-4ca2-b69d-160d9f66eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally print the confusion matrix for the best model (GradientBoostingClassifier)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d05d3f-0da0-416b-8045-538886acf5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3b813-1097-463d-a5c2-f083dd7e3b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1361e2-012c-448e-8795-fbf5fd0c57fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94194252-152e-4f47-ae90-b79ebfe702bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
