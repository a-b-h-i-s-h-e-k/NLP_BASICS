{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0b1191-d796-4271-9c43-01495c390513",
   "metadata": {},
   "source": [
    "--> Stop words are a set of commonly used words in a language. Examples of stop words in English are “a,” “the,” “is,” “are,” etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so widely used that they carry very little useful information.\n",
    "\n",
    "--> What are Stop Words? Stop words are the most frequently used words in a natural language like in, on, a, an, the, etc., in the English language. While analyzing data, these words might not add much value to the meaning of the data, and hence they can be filtered out to focus more on the essential words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549a079-6f81-401e-8a5f-9ed3344589b4",
   "metadata": {},
   "source": [
    "Q. When Should I not remove Stop Words?\n",
    "- This is a good movie ---> remove stop words ---> good movie\n",
    "- This is a not good movie ---> remove stop words ---> good movie\n",
    "\n",
    "- When we are doing language translation,  here if i remove stop words in pre-processing stage, all i get some sentence w/o stop words that make may be non sense.\n",
    "\n",
    "- Chat bot, Q&A System\n",
    "- Language Translation\n",
    "- Any case where valuable information is lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6568c6ca-0f10-4267-bd30-ad495d8ca659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b91a92-736b-4f68-82bb-7a446c50e058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d26005-f1d6-40d7-ba5b-494cd9f2ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0528a5-960f-4d9b-b4a2-86851066ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "just\n",
      "our\n",
      "the\n",
      "part\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"We just opened our wings, the flying part is coming soon\")\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e1a83f-da84-4be7-81bb-7daaef39c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop]\n",
    "    return \" \".join(no_stop_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54cb65b-9a6b-4892-8987-b10308dcd477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Musk wants time prepare trial'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Musk wants time to prepare for a trial over his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d66bf6-8440-43bc-9242-0f699f8094ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'divine brother'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"The other is not other but your divine brother\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09fbba-f9b8-4c9e-bd11-190da1481814",
   "metadata": {},
   "source": [
    "Removing stop words from pandas dataframe text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35ab403-51d7-4ecf-9a17-fbd960c76999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"doj_press.json\",lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07414798-5620-42bd-8643-60cfbaa478ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>16-735</td>\n",
       "      <td>Yuengling to Upgrade Environmental Measures to...</td>\n",
       "      <td>The Department of Justice and the U.S. Environ...</td>\n",
       "      <td>2016-06-23T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13083</th>\n",
       "      <td>10-473</td>\n",
       "      <td>Zarein Ahmedzay Pleads Guilty to Terror Violat...</td>\n",
       "      <td>The Justice Department announced that Zarein...</td>\n",
       "      <td>2010-04-23T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Office of the Attorney General]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>17-045</td>\n",
       "      <td>Zimmer Biomet Holdings Inc. Agrees to Pay $17....</td>\n",
       "      <td>Subsidiary Agrees to Plead Guilty to Violating...</td>\n",
       "      <td>2017-01-12T00:00:00-05:00</td>\n",
       "      <td>[Foreign Corruption]</td>\n",
       "      <td>[Criminal Division, Criminal - Criminal Fraud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13085</th>\n",
       "      <td>17-252</td>\n",
       "      <td>ZTE Corporation Agrees to Plead Guilty and Pay...</td>\n",
       "      <td>ZTE Corporation has agreed to enter a guilty p...</td>\n",
       "      <td>2017-03-07T00:00:00-05:00</td>\n",
       "      <td>[Asset Forfeiture, Counterintelligence and Exp...</td>\n",
       "      <td>[National Security Division (NSD), USAO - Texa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13086</th>\n",
       "      <td>17-304</td>\n",
       "      <td>ZTE Corporation Pleads Guilty for  Violating U...</td>\n",
       "      <td>ZTE Corporation pleaded guilty today to conspi...</td>\n",
       "      <td>2017-03-22T00:00:00-04:00</td>\n",
       "      <td>[Counterintelligence and Export Control]</td>\n",
       "      <td>[National Security Division (NSD), USAO - Texa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "13082  16-735  Yuengling to Upgrade Environmental Measures to...   \n",
       "13083  10-473  Zarein Ahmedzay Pleads Guilty to Terror Violat...   \n",
       "13084  17-045  Zimmer Biomet Holdings Inc. Agrees to Pay $17....   \n",
       "13085  17-252  ZTE Corporation Agrees to Plead Guilty and Pay...   \n",
       "13086  17-304  ZTE Corporation Pleads Guilty for  Violating U...   \n",
       "\n",
       "                                                contents  \\\n",
       "13082  The Department of Justice and the U.S. Environ...   \n",
       "13083    The Justice Department announced that Zarein...   \n",
       "13084  Subsidiary Agrees to Plead Guilty to Violating...   \n",
       "13085  ZTE Corporation has agreed to enter a guilty p...   \n",
       "13086  ZTE Corporation pleaded guilty today to conspi...   \n",
       "\n",
       "                            date  \\\n",
       "13082  2016-06-23T00:00:00-04:00   \n",
       "13083  2010-04-23T00:00:00-04:00   \n",
       "13084  2017-01-12T00:00:00-05:00   \n",
       "13085  2017-03-07T00:00:00-05:00   \n",
       "13086  2017-03-22T00:00:00-04:00   \n",
       "\n",
       "                                                  topics  \\\n",
       "13082                                      [Environment]   \n",
       "13083                                                 []   \n",
       "13084                               [Foreign Corruption]   \n",
       "13085  [Asset Forfeiture, Counterintelligence and Exp...   \n",
       "13086           [Counterintelligence and Export Control]   \n",
       "\n",
       "                                              components  \n",
       "13082       [Environment and Natural Resources Division]  \n",
       "13083                   [Office of the Attorney General]  \n",
       "13084  [Criminal Division, Criminal - Criminal Fraud ...  \n",
       "13085  [National Security Division (NSD), USAO - Texa...  \n",
       "13086  [National Security Division (NSD), USAO - Texa...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ea24de3-3e6e-48c6-b0e1-887b8d015f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Convicted Bomb Plotter Sentenced to 30 Years</td>\n",
       "      <td>PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...</td>\n",
       "      <td>2014-10-01T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[National Security Division (NSD)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-919</td>\n",
       "      <td>$1 Million in Restitution Payments Announced t...</td>\n",
       "      <td>WASHINGTON – North Carolina’s Waccamaw River...</td>\n",
       "      <td>2012-07-25T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1002</td>\n",
       "      <td>$1 Million Settlement Reached for Natural Reso...</td>\n",
       "      <td>BOSTON– A $1-million settlement has been...</td>\n",
       "      <td>2011-08-03T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10-015</td>\n",
       "      <td>10 Las Vegas Men Indicted \\r\\nfor Falsifying V...</td>\n",
       "      <td>WASHINGTON—A federal grand jury in Las Vegas...</td>\n",
       "      <td>2010-01-08T00:00:00-05:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0     None       Convicted Bomb Plotter Sentenced to 30 Years   \n",
       "1  12-919   $1 Million in Restitution Payments Announced t...   \n",
       "2  11-1002  $1 Million Settlement Reached for Natural Reso...   \n",
       "3   10-015  10 Las Vegas Men Indicted \\r\\nfor Falsifying V...   \n",
       "4   18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "\n",
       "                                            contents  \\\n",
       "0  PORTLAND, Oregon. – Mohamed Osman Mohamud, 23,...   \n",
       "1    WASHINGTON – North Carolina’s Waccamaw River...   \n",
       "2        BOSTON– A $1-million settlement has been...   \n",
       "3    WASHINGTON—A federal grand jury in Las Vegas...   \n",
       "4  The U.S. Department of Justice, the U.S. Envir...   \n",
       "\n",
       "                        date         topics  \\\n",
       "0  2014-10-01T00:00:00-04:00             []   \n",
       "1  2012-07-25T00:00:00-04:00             []   \n",
       "2  2011-08-03T00:00:00-04:00             []   \n",
       "3  2010-01-08T00:00:00-05:00             []   \n",
       "4  2018-07-09T00:00:00-04:00  [Environment]   \n",
       "\n",
       "                                     components  \n",
       "0            [National Security Division (NSD)]  \n",
       "1  [Environment and Natural Resources Division]  \n",
       "2  [Environment and Natural Resources Division]  \n",
       "3  [Environment and Natural Resources Division]  \n",
       "4  [Environment and Natural Resources Division]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8152ce6d-e1f5-4fe5-873a-f00941f029a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13087, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa129f32-c8e8-48f8-81d7-826f8cad2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(df.topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70bba6a-b8c3-4e1c-812f-42dcccb3fec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7   14-1412  14 Indicted in Connection with New England Com...   \n",
       "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "\n",
       "                                             contents  \\\n",
       "4   The U.S. Department of Justice, the U.S. Envir...   \n",
       "7   A 131-count criminal indictment was unsealed t...   \n",
       "19  The United States Attorney’s Office for the Mi...   \n",
       "22  21st Century Oncology LLC, has agreed to pay $...   \n",
       "23  21st Century Oncology Inc. and certain of its ...   \n",
       "\n",
       "                         date                                 topics  \\\n",
       "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "\n",
       "                                           components  \n",
       "4        [Environment and Natural Resources Division]  \n",
       "7                                    [Civil Division]  \n",
       "19  [Environment and Natural Resources Division, U...  \n",
       "22                                   [Civil Division]  \n",
       "23           [Civil Division, USAO - Florida, Middle]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out those rows that do not have any topics associated with the case\n",
    "\n",
    "df = df[df[\"topics\"].str.len() != 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e191ffb-8080-4188-aeb0-eb918c34a010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4688, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6be95f3-fafe-4826-9289-feaccb0bbaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =df.head(100)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b4af78b-056e-452a-aa22-faa091f87226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"contents_new\"] = df.contents.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa7399ee-5eb9-4783-9927-93817fd6a939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "      <th>contents_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "      <td>U.S. Department Justice , U.S. Environmental P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>131 - count criminal indictment unsealed today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "      <td>United States Attorney Office Middle District ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>21st Century Oncology LLC , agreed pay $ 19.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "      <td>21st Century Oncology Inc. certain subsidiarie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>15-1359</td>\n",
       "      <td>Alaska Plastic Surgeon Convicted of Wire Fraud...</td>\n",
       "      <td>Doctor Hid Millions in Secret Accounts in Pana...</td>\n",
       "      <td>2015-11-04T00:00:00-05:00</td>\n",
       "      <td>[Tax]</td>\n",
       "      <td>[Tax Division]</td>\n",
       "      <td>Doctor Hid Millions Secret Accounts Panama Ala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>16-396</td>\n",
       "      <td>Alaska Plastic Surgeon Sentenced to Prison for...</td>\n",
       "      <td>Defendant Concealed Bank Accounts in Panama an...</td>\n",
       "      <td>2016-04-04T00:00:00-04:00</td>\n",
       "      <td>[Tax]</td>\n",
       "      <td>[Tax Division]</td>\n",
       "      <td>Defendant Concealed Bank Accounts Panama Costa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>17-736</td>\n",
       "      <td>Alaskan Commercial Fishing Couple Charged with...</td>\n",
       "      <td>An Alaskan couple was charged in federal court...</td>\n",
       "      <td>2017-07-26T00:00:00-04:00</td>\n",
       "      <td>[Tax]</td>\n",
       "      <td>[Tax Division, USAO - Alaska]</td>\n",
       "      <td>Alaskan couple charged federal court Juneau , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>18-717</td>\n",
       "      <td>Alaskan Husband And Wife Plead Guilty To Willf...</td>\n",
       "      <td>A husband and wife pleaded guilty yesterday to...</td>\n",
       "      <td>2018-06-01T00:00:00-04:00</td>\n",
       "      <td>[Tax]</td>\n",
       "      <td>[Tax Division]</td>\n",
       "      <td>husband wife pleaded guilty yesterday counts w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>16-1345</td>\n",
       "      <td>Alaskan Oncologist Indicted for Tax Evasion</td>\n",
       "      <td>A resident of Big Lake, Alaska was indicted on...</td>\n",
       "      <td>2016-11-17T00:00:00-05:00</td>\n",
       "      <td>[Tax]</td>\n",
       "      <td>[Tax Division]</td>\n",
       "      <td>resident Big Lake , Alaska indicted counts tax...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "4     18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7    14-1412  14 Indicted in Connection with New England Com...   \n",
       "19   17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22   15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23   17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "..       ...                                                ...   \n",
       "316  15-1359  Alaska Plastic Surgeon Convicted of Wire Fraud...   \n",
       "318   16-396  Alaska Plastic Surgeon Sentenced to Prison for...   \n",
       "321   17-736  Alaskan Commercial Fishing Couple Charged with...   \n",
       "322   18-717  Alaskan Husband And Wife Plead Guilty To Willf...   \n",
       "324  16-1345        Alaskan Oncologist Indicted for Tax Evasion   \n",
       "\n",
       "                                              contents  \\\n",
       "4    The U.S. Department of Justice, the U.S. Envir...   \n",
       "7    A 131-count criminal indictment was unsealed t...   \n",
       "19   The United States Attorney’s Office for the Mi...   \n",
       "22   21st Century Oncology LLC, has agreed to pay $...   \n",
       "23   21st Century Oncology Inc. and certain of its ...   \n",
       "..                                                 ...   \n",
       "316  Doctor Hid Millions in Secret Accounts in Pana...   \n",
       "318  Defendant Concealed Bank Accounts in Panama an...   \n",
       "321  An Alaskan couple was charged in federal court...   \n",
       "322  A husband and wife pleaded guilty yesterday to...   \n",
       "324  A resident of Big Lake, Alaska was indicted on...   \n",
       "\n",
       "                          date                                 topics  \\\n",
       "4    2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7    2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19   2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22   2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23   2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "..                         ...                                    ...   \n",
       "316  2015-11-04T00:00:00-05:00                                  [Tax]   \n",
       "318  2016-04-04T00:00:00-04:00                                  [Tax]   \n",
       "321  2017-07-26T00:00:00-04:00                                  [Tax]   \n",
       "322  2018-06-01T00:00:00-04:00                                  [Tax]   \n",
       "324  2016-11-17T00:00:00-05:00                                  [Tax]   \n",
       "\n",
       "                                            components  \\\n",
       "4         [Environment and Natural Resources Division]   \n",
       "7                                     [Civil Division]   \n",
       "19   [Environment and Natural Resources Division, U...   \n",
       "22                                    [Civil Division]   \n",
       "23            [Civil Division, USAO - Florida, Middle]   \n",
       "..                                                 ...   \n",
       "316                                     [Tax Division]   \n",
       "318                                     [Tax Division]   \n",
       "321                      [Tax Division, USAO - Alaska]   \n",
       "322                                     [Tax Division]   \n",
       "324                                     [Tax Division]   \n",
       "\n",
       "                                          contents_new  \n",
       "4    U.S. Department Justice , U.S. Environmental P...  \n",
       "7    131 - count criminal indictment unsealed today...  \n",
       "19   United States Attorney Office Middle District ...  \n",
       "22   21st Century Oncology LLC , agreed pay $ 19.75...  \n",
       "23   21st Century Oncology Inc. certain subsidiarie...  \n",
       "..                                                 ...  \n",
       "316  Doctor Hid Millions Secret Accounts Panama Ala...  \n",
       "318  Defendant Concealed Bank Accounts Panama Costa...  \n",
       "321  Alaskan couple charged federal court Juneau , ...  \n",
       "322  husband wife pleaded guilty yesterday counts w...  \n",
       "324  resident Big Lake , Alaska indicted counts tax...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ce3ba6-7b6f-4433-8666-bf91dbee3587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6286"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.contents[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a70dc2d-6195-4db6-8a52-1bf491b2323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4810"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.contents_new[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bf6c44a-8f55-4dd8-89f8-6076c2a58b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The U.S. Department of Justice, the U.S. Environmental Protection Agency (EPA), and the Rhode Island Department of Environmental Management (RIDEM) announced today that two subsidiaries of Stanley Black & Decker Inc.—Emhart Industries Inc. and Black & Decker Inc.—have agreed to clean up dioxin conta'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.contents[4][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04bb959c-fd68-4d51-afe1-9803c288119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Department Justice , U.S. Environmental Protection Agency ( EPA ) , Rhode Island Department Environmental Management ( RIDEM ) announced today subsidiaries Stanley Black & Decker Inc.—Emhart Industries Inc. Black & Decker Inc.—have agreed clean dioxin contaminated sediment soil Centredale Manor'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.contents_new[4][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328da84-2ae4-4a2c-85b4-8abf217e657b",
   "metadata": {},
   "source": [
    "\n",
    "Examples where removing stop words can create a problem\n",
    "\n",
    "# (1) Sentiment detection: Not always but in some cases, based on your dataset it can change the sentiment of a sentence if you remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f8b5872-41ea-4a8d-be00-51641e6db48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good movie'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"this is a good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f273fa-5277-442d-8419-f7d6cc55bd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good movie'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"this is not a good movie\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa7a9d-c243-433f-95bd-b7ed558c67df",
   "metadata": {},
   "source": [
    "# (2) Language translation: Say you want to translate following sentence from english to telugu. Before actual translation if you remove stop words and then translate, it will produce horrible result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ea08996-601e-4d2e-a537-6e745426e2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dhaval ?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"how are you doing dhaval?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052eb408-a65d-4ba8-9d1d-9e899d988858",
   "metadata": {},
   "source": [
    "# (3) Chat bot or any Q&A system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8180668-0f8a-46a6-b687-fc42d1f080fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find yoga mat website . help ?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"I don't find yoga mat on your website. Can you help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111ab90-3708-4f25-951b-f6f6f80a2457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102abd6e-8125-4a7b-91fa-1ffe31ebb99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69351a-6680-4da0-b61c-6984f5da7f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6019ff-0162-4ad3-9420-d5af98a9c859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d9d4a-e05e-4e29-9fbe-92ba094c332a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b791201-dca6-461c-a2e8-e511ffb101fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555b15f-1501-4d30-8f68-8de346ba3065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e997c498-5785-440c-86b9-00969b8f7c3c",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f312a27-efec-49b2-af61-6199f83fcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ed82f-e42b-4fe2-b0c7-d73198aff6cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Exercise1:\n",
    "\n",
    "    From a Given Text, Count the number of stop words in it.\n",
    "    Print the percentage of stop word tokens compared to all tokens in a given text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e09d089c-0785-4b64-8606-60940842c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Stop words presented in the given text: 40\n",
      "Percentage of Stop words presented in the given text: 25.0 %\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Thor: Love and Thunder is a 2022 American superhero film based on Marvel Comics featuring the character Thor, produced by Marvel Studios and \n",
    "distributed by Walt Disney Studios Motion Pictures. It is the sequel to Thor: Ragnarok (2017) and the 29th film in the Marvel Cinematic Universe (MCU).\n",
    "The film is directed by Taika Waititi, who co-wrote the script with Jennifer Kaytin Robinson, and stars Chris Hemsworth as Thor alongside Christian Bale, Tessa Thompson,\n",
    "Jaimie Alexander, Waititi, Russell Crowe, and Natalie Portman. In the film, Thor attempts to find inner peace, but must return to action and recruit Valkyrie (Thompson),\n",
    "Korg (Waititi), and Jane Foster (Portman)—who is now the Mighty Thor—to stop Gorr the God Butcher (Bale) from eliminating all gods.\n",
    "'''\n",
    "\n",
    "#step1: Create the object 'doc' for the given text using nlp()\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "#step2: define the variables to keep track of stopwords count and total words count\n",
    "stop_words_count = 0\n",
    "total_words_count = 0\n",
    "\n",
    "\n",
    "#step3: iterate through all the words in the document\n",
    "for token in doc:\n",
    "  if token.is_stop:         #check whether given token is stop word or not and increment accordingly       \n",
    "    stop_words_count += 1\n",
    "  total_words_count +=  1   #increment the total_words_count\n",
    "\n",
    "\n",
    "#step4: print the count of stop words\n",
    "print(f\"Total Stop words presented in the given text: {stop_words_count}\")\n",
    "    \n",
    "\n",
    "#step5: print the percentage of stop words compared to total words in the text\n",
    "percentage_stop_words = (stop_words_count / total_words_count) * 100\n",
    "print(f\"Percentage of Stop words presented in the given text: {percentage_stop_words} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e635c-3d33-4849-945a-be82e9851c09",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Exercise2:\n",
    "\n",
    "    Spacy default implementation considers \"not\" as a stop word. But in some scenarios removing 'not' will completely change the meaning of the statement/text. For Example, consider these two statements:\n",
    "\n",
    "    - this is a good movie       ----> Positive Statement\n",
    "    - this is not a good movie   ----> Negative Statement\n",
    "\n",
    "    So, after applying stopwords to those 2 texts, both will return \"good movie\" and does not respect the polarity/sentiments of text.\n",
    "\n",
    "    Now, your task is to remove this stop word \"not\" in spaCy and help in distinguishing the texts.\n",
    "\n",
    "    Hint: GOOGLE IT! Google is your friend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc9750fc-0c1f-48c0-8617-aba6b43cef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text1: good movie\n",
      "Text2: not good movie\n"
     ]
    }
   ],
   "source": [
    "#use this pre-processing function to pass the text and to remove all the stop words and finally get the cleaned form\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop]\n",
    "    return \" \".join(no_stop_words)       \n",
    "\n",
    "\n",
    "#Step1: remove the stopword 'not' in spacy\n",
    "nlp.vocab['not'].is_stop = False\n",
    "\n",
    "\n",
    "#step2: send the two texts given above into the pre-process function and store the transformed texts\n",
    "positive_text = preprocess('this is a good movie')\n",
    "negative_text = preprocess('this is not a good movie')\n",
    "\n",
    "\n",
    "#step3: finally print those 2 transformed texts\n",
    "print(f\"Text1: {positive_text}\")\n",
    "print(f\"Text2: {negative_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad9409-68db-48df-868f-f1fa3c28f22a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Exercise3:\n",
    "\n",
    "    From a given text, output the most frequently used token after removing all the stop word tokens and punctuations in it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b3bdb21-cec5-4820-9e09-40ea35caaed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum frequency word: India\n"
     ]
    }
   ],
   "source": [
    "text = ''' The India men's national cricket team, also known as Team India or the Men in Blue, represents India in men's international cricket.\n",
    "It is governed by the Board of Control for Cricket in India (BCCI), and is a Full Member of the International Cricket Council (ICC) with Test,\n",
    "One Day International (ODI) and Twenty20 International (T20I) status. Cricket was introduced to India by British sailors in the 18th century, and the \n",
    "first cricket club was established in 1792. India's national cricket team played its first Test match on 25 June 1932 at Lord's, becoming the sixth team to be\n",
    "granted test cricket status.\n",
    "'''\n",
    "\n",
    "\n",
    "#step1: Create the object 'doc' for the given text using nlp()\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "#step2: remove all the stop words and punctuations and store all the remaining tokens in a new list\n",
    "remaining_tokens = []\n",
    "for token in doc:\n",
    "  if token.is_stop or token.is_punct:    #check whether a given token is stop word or punctuations\n",
    "    continue\n",
    "  remaining_tokens.append(token.text)\n",
    "\n",
    "\n",
    "#step3: create a new dictionary and get the frequency of words by iterating through the list which contains stored tokens  \n",
    "frequency_tokens = {}\n",
    "for token in remaining_tokens:\n",
    "  if token != '\\n' and token != ' ':      #As spacy considers new line and empty spaces as seperate token, it's better to ignore them\n",
    "    if token not in frequency_tokens:     #if a particular token occurs for the first time, we initialise it to 1\n",
    "      frequency_tokens[token] = 1\n",
    "    else:\n",
    "      frequency_tokens[token] += 1        #if a partcular token is already present, then increment by 1 based on value already presented\n",
    "\n",
    "\n",
    "#step4: get the maximum frequency word\n",
    "max_freq_word = max(frequency_tokens.keys(), key=(lambda key: frequency_tokens[key]))\n",
    "\n",
    "\n",
    "#step5: finally print the result\n",
    "print(f\"Maximum frequency word: {max_freq_word}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528dc37-f37a-4186-9e25-6978d51f8cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd2268-1ffd-4853-b2e5-9a6b453d57eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1367a72-4b42-4f83-b63e-9cc2c69b2955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07512e2-17f5-415f-877c-3a625eb3d8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869acacb-a564-4e9d-b3b9-9dd5ec65d122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81886865-f694-485e-b42f-510ece7df909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4ba96-c19b-448f-aa5b-a5bc23644a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
